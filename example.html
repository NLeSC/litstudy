<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Example of using litstudy &mdash; litstudy 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API reference" href="api/index.html" />
    <link rel="prev" title="Welcome to litstudy’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> litstudy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example of using litstudy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Imports">Imports</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Collecting-the-dataset">Collecting the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#General-statistics">General statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Network-analysis">Network analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Topic-modeling">Topic modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Advanced-topic-modeling">Advanced topic modeling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">litstudy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Example of using litstudy</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/example.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Example-of-using-litstudy">
<h1>Example of using litstudy<a class="headerlink" href="#Example-of-using-litstudy" title="Permalink to this headline"></a></h1>
<p>This notebook shows an example of how to use <code class="docutils literal notranslate"><span class="pre">litstudy</span></code> from inside a Jupyter notebook. It shows how to load a dataset, plot statistics, topic modeling, network analysis, and some more advanced features.</p>
<p>This notebook focuses on the topic of programming model for GPUs. GPUs (Graphic Processing Units) are specialized processors that are used in many data centers and supercomputers for data processing and machine learning. However, programming these devices remaining difficult, which is why there is a plethora of research on developing programming models for them.</p>
<section id="Imports">
<h2>Imports<a class="headerlink" href="#Imports" title="Permalink to this headline"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Import other libraries
import os
import sys
import numpy as np

import matplotlib.pyplot as plt
plt.rcParams[&#39;figure.figsize&#39;] = (10, 6)

import seaborn as sbs
sbs.set(&#39;paper&#39;)

# Import litstudy
path = os.path.abspath(os.path.join(&#39;..&#39;))
if path not in sys.path:
    sys.path.append(path)

import litstudy
</pre></div>
</div>
</div>
</section>
<section id="Collecting-the-dataset">
<h2>Collecting the dataset<a class="headerlink" href="#Collecting-the-dataset" title="Permalink to this headline"></a></h2>
<p>For this, example, we have searched both IEEE Xplore and Springer Link for the query <code class="docutils literal notranslate"><span class="pre">&quot;GPU&quot;</span> <span class="pre">and</span> <span class="pre">&quot;programming</span> <span class="pre">model&quot;</span></code>. IEEE Xplore gives 5 CSV files (1 per page) and Springer Link gives a single CSV file. We load all files and merge the resulting document sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Load the CSV files
docs1 = litstudy.load_ieee_csv(&#39;data/ieee_1.csv&#39;)
docs2 = litstudy.load_ieee_csv(&#39;data/ieee_2.csv&#39;)
docs3 = litstudy.load_ieee_csv(&#39;data/ieee_3.csv&#39;)
docs4 = litstudy.load_ieee_csv(&#39;data/ieee_4.csv&#39;)
docs5 = litstudy.load_ieee_csv(&#39;data/ieee_5.csv&#39;)
docs_ieee = docs1 | docs2 | docs3 | docs4 | docs5
print(len(docs_ieee), &#39;papers loaded from IEEE&#39;)

docs_springer = litstudy.load_springer_csv(&#39;data/springer.csv&#39;)
print(len(docs_springer), &#39;papers loaded from Springer&#39;)

# Merge the two document sets
docs_csv = docs_ieee | docs_springer
print(len(docs_csv), &#39;papers loaded from CSV&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
441 papers loaded from IEEE
1000 papers loaded from Springer
1441 papers loaded from CSV
</pre></div></div>
</div>
<p>We can also exclude some papers that we are not interested in. Here, we load a document set from a RIS file and subtract these documents from our original document set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs_exclude = litstudy.load_ris_file(&#39;data/exclude.ris&#39;)
docs_remaining = docs_csv - docs_exclude

print(len(docs_exclude), &#39;papers were excluded&#39;)
print(len(docs_remaining), &#39;paper remaining&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1 papers were excluded
1440 paper remaining
</pre></div></div>
</div>
<p>The metadata provided by the CSV files is not great. To solve this, we can lookup the papers on Scopus using <code class="docutils literal notranslate"><span class="pre">refine_scopus</span></code>. This function returns two sets: the set of Scopus documents that were found and the set of original documents not were not found on Scopus. We have two options here: (1) merge the two sets back into one set or (2) discard the documents that were not found. We chose the second option here for simplicity.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import logging
logging.getLogger().setLevel(logging.CRITICAL)

docs_scopus, docs_notfound = litstudy.refine_scopus(docs_remaining)

print(len(docs_scopus), &#39;papers found on Scopus&#39;)
print(len(docs_notfound), &#39;papers were not found and were discarded&#39;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 1440/1440 [00:04&lt;00:00, 335.79it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1387 papers found on Scopus
53 papers were not found and were discarded
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>Next, we plot the number of documents per publication source.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_year_histogram(docs_scopus);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_11_0.png" src="_images/example_11_0.png" />
</div>
</div>
<p>It appears there is one document from 1997. This is likely an error since GPUs were not used for general purpose computing before 2006. We can remove this document by filtering on year of publication.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs = docs_scopus.filter_docs(lambda d: d.publication_year &gt;= 2000)
</pre></div>
</div>
</div>
<p>Finally, we print how many papers are left</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(len(docs), &#39;papers remaining&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1386 papers remaining
</pre></div></div>
</div>
</section>
<section id="General-statistics">
<h2>General statistics<a class="headerlink" href="#General-statistics" title="Permalink to this headline"></a></h2>
<p>litstudy supports plot many general statistics of the document set as histograms. We show some simple examples below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_year_histogram(docs, vertical=True);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_18_0.png" src="_images/example_18_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_affiliation_histogram(docs, limit=15);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_19_0.png" src="_images/example_19_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_author_histogram(docs);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_20_0.png" src="_images/example_20_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_language_histogram(docs);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_21_0.png" src="_images/example_21_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_number_authors_histogram(docs);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_22_0.png" src="_images/example_22_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># This names are long, which is why a short abbreviation is provided.
mapping = {
    &quot;IEEE International parallel and distributed processing symposium IPDPS&quot;: &quot;IEEE IPDPS&quot;,
    &quot;IEEE International parallel and distributed processing symposium workshops IPDPSW&quot;: &quot;IEEE IPDPS Workshops&quot;,
}

litstudy.plot_source_histogram(docs, mapper=mapping, limit=15);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_23_0.png" src="_images/example_23_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_country_histogram(docs, limit=15);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_24_0.png" src="_images/example_24_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.plot_continent_histogram(docs);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_25_0.png" src="_images/example_25_0.png" />
</div>
</div>
</section>
<section id="Network-analysis">
<h2>Network analysis<a class="headerlink" href="#Network-analysis" title="Permalink to this headline"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># litstudy.plot_cocitation_network(docs, max_edges=500)
</pre></div>
</div>
</div>
</section>
<section id="Topic-modeling">
<h2>Topic modeling<a class="headerlink" href="#Topic-modeling" title="Permalink to this headline"></a></h2>
<p>litstudy supports automatic topic discovery based on the words used in documents abstracts. We show an example below. First, we need to build a corpus from the document set. Note that <code class="docutils literal notranslate"><span class="pre">build_corpus</span></code> supports many arguments to tweak the preprocessing stage of building the corpus. In this example, we pass <code class="docutils literal notranslate"><span class="pre">ngram_threshold=0.85</span></code> which will add commonly used n-grams (i.e., frequent consecutive words) to the corpus.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>corpus = litstudy.build_corpus(docs, ngram_threshold=0.8)
</pre></div>
</div>
</div>
<p>We can compute a word distribution using <code class="docutils literal notranslate"><span class="pre">litstudy.compute_word_distribution</span></code> which how often each word occurs across all documents. In this example, we filter out the bigrams by only showing the words that contain an <code class="docutils literal notranslate"><span class="pre">_</span></code>. We see that words such as <code class="docutils literal notranslate"><span class="pre">artificial</span> <span class="pre">intelligence</span></code> and <code class="docutils literal notranslate"><span class="pre">trade</span> <span class="pre">offs</span></code> have been recognized as common bigrams.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>litstudy.compute_word_distribution(corpus).filter(like=&#39;_&#39;, axis=0).sort_index()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>artificial_intelligence</th>
      <td>13</td>
    </tr>
    <tr>
      <th>author_exclusive</th>
      <td>41</td>
    </tr>
    <tr>
      <th>berlin_heidelberg</th>
      <td>83</td>
    </tr>
    <tr>
      <th>chinese_academy</th>
      <td>6</td>
    </tr>
    <tr>
      <th>coarse_grained</th>
      <td>16</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>synthetic_aperture</th>
      <td>7</td>
    </tr>
    <tr>
      <th>trade_offs</th>
      <td>10</td>
    </tr>
    <tr>
      <th>unified_device</th>
      <td>108</td>
    </tr>
    <tr>
      <th>xeon_phi</th>
      <td>21</td>
    </tr>
    <tr>
      <th>zhejiang_university</th>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>63 rows × 1 columns</p>
</div></div>
</div>
<p>Let’s visualize the word distribution from this corpus.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(20, 3))
litstudy.plot_word_distribution(corpus, limit=50, title=&quot;Top words&quot;, vertical=True, label_rotation=45);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_34_0.png" src="_images/example_34_0.png" />
</div>
</div>
<p>The word distribution looks like what we would expect. Next, we run an NMF topic model for 15 topics.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>num_topics = 15
topic_model = litstudy.train_nmf_model(corpus, num_topics, max_iter=250)
</pre></div>
</div>
</div>
<p>To understad the result of NMF, we can, for examp, print the top 3 words for each topics.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for topic_id in range(num_topics):
    print(f&#39;topic {topic_id + 1}:&#39;, topic_model.top_topic_tokens(topic_id, limit=3))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
topic 1: [&#39;cluster&#39;, &#39;mpi&#39;, &#39;node&#39;]
topic 2: [&#39;mapreduce&#39;, &#39;big&#39;, &#39;data&#39;]
topic 3: [&#39;simulation&#39;, &#39;particle&#39;, &#39;numerical&#39;]
topic 4: [&#39;learning&#39;, &#39;network&#39;, &#39;deep&#39;]
topic 5: [&#39;fpga&#39;, &#39;memory&#39;, &#39;access&#39;]
topic 6: [&#39;openacc&#39;, &#39;compiler&#39;, &#39;openmp&#39;]
topic 7: [&#39;image&#39;, &#39;segmentation&#39;, &#39;algorithm&#39;]
topic 8: [&#39;sequence&#39;, &#39;alignment&#39;, &#39;protein&#39;]
topic 9: [&#39;video&#39;, &#39;decoding&#39;, &#39;encoding&#39;]
topic 10: [&#39;gpgpu&#39;, &#39;cuda&#39;, &#39;code&#39;]
topic 11: [&#39;energy&#39;, &#39;heterogeneous&#39;, &#39;power&#39;]
topic 12: [&#39;graph&#39;, &#39;vertex&#39;, &#39;framework&#39;]
topic 13: [&#39;scheduling&#39;, &#39;task&#39;, &#39;heterogeneous&#39;]
topic 14: [&#39;intel&#39;, &#39;matrix&#39;, &#39;phi&#39;]
topic 15: [&#39;opencl&#39;, &#39;portability&#39;, &#39;benchmark&#39;]
</pre></div></div>
</div>
<p>An alternative way to visualize the output of NMF is to plot each discovered topic as a word cloud. The size of the words indicate the importance of each word for that topic.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(15, 5))
litstudy.nlp.plot_topic_clouds(topic_model, ncols=5);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_40_0.png" src="_images/example_40_0.png" />
</div>
</div>
<p>These 15 topics look promising. For example, there is one topic on graphs, one on OpenACC, one on OpenCL, one on FPGAs, etc.</p>
<p>We can visualize the results as a “landscape” plot. This is a visual appealing way to place documents on a map. The documents are placed such that similar documents are located closed to each other. However, this is a non-linear embedding so the distances between the documents are not linear.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(20, 20))
litstudy.plot_embedding(corpus, topic_model);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_42_0.png" src="_images/example_42_0.png" />
</div>
</div>
</section>
<section id="Advanced-topic-modeling">
<h2>Advanced topic modeling<a class="headerlink" href="#Advanced-topic-modeling" title="Permalink to this headline"></a></h2>
<p>We can combine the results of topic modeling with the plotting of statistics. Here we show we a simple example.</p>
<p>First, we find the topic id for the topic that most strongly belongs to “deep_learning”. Next, we annotate the document set with a “dl_topic” tag for document that strongly belong to this topic (i.e., weight above a certain threshold).</p>
<p>After this, we define two groups: documents that have the tag “dl_topic” and documents that do not have this tag. We can, for example, print the publications over the years to see if interest in deep learning has increased or decreased over the years.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>topic_id = topic_model.best_topic_for_token(&#39;deep_learning&#39;)

threshold = 0.2
dl_topic = topic_model.doc2topic[:, topic_id] &gt; threshold

docs = docs.add_property(&#39;dl_topic&#39;, dl_topic)


groups = {
    &#39;deep learning related&#39;: &#39;dl_topic&#39;,
    &#39;other&#39;: &#39;1 - dl_topic&#39;,
}

litstudy.plot_year_histogram(docs, groups=groups, stacked=True);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_45_0.png" src="_images/example_45_0.png" />
</div>
</div>
<p>The histogram shows that interest in deep learning is clearly rising over the years. We can even calculate the exact amount by calculating the percentage of documents on deep learning each year. The example below shows that this percentage has increased from just 3.4% in 2011 to 13.6% in 2021.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>table = litstudy.compute_year_histogram(docs, groups=groups)
table = (table.T / table.sum(axis=1)).T * 100
table
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>deep learning related</th>
      <th>other</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2005</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2007</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>6.250000</td>
      <td>93.750000</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>2.127660</td>
      <td>97.872340</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>3.409091</td>
      <td>96.590909</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>2.941176</td>
      <td>97.058824</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>3.738318</td>
      <td>96.261682</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>3.305785</td>
      <td>96.694215</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>9.565217</td>
      <td>90.434783</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>7.272727</td>
      <td>92.727273</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>3.448276</td>
      <td>96.551724</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>7.200000</td>
      <td>92.800000</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>9.027778</td>
      <td>90.972222</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>9.734513</td>
      <td>90.265487</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>13.600000</td>
      <td>86.400000</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>14.285714</td>
      <td>85.714286</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Alternatively, we can plot the two groups for the publications source. We can see that some journals/conferences have more focus on deep learning (for example, “Neural Computing and Applications”), while others have no or few publications on this topic (for example, “Journal of Real Time Image Processing”).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(10, 10))

dl_topic = topic_model.doc2topic[:, topic_id] &gt; .1
docs = docs.add_property(&#39;dl_topic&#39;, dl_topic)

litstudy.plot_source_histogram(docs, groups=groups, limit=25, stacked=True);
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_49_0.png" src="_images/example_49_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to litstudy’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api/index.html" class="btn btn-neutral float-right" title="API reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, S. Heldens, H. Dreuning, A. Sclocco.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>