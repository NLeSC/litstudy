<!DOCTYPE html>
<html class="writer-html5" lang="english" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Example of using litstudy &mdash; litstudy 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/style.css" type="text/css" />
      <link rel="stylesheet" href="_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=a34077ea"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Frequently Asked Questions" href="faq.html" />
    <link rel="prev" title="Installation Guide" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            litstudy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example of using litstudy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Imports">Imports</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Collecting-the-dataset">Collecting the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#General-statistics">General statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Network-analysis">Network analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Topic-modeling">Topic modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Advanced-topic-modeling">Advanced topic modeling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NLeSC/litstudy">Github repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">litstudy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Example of using litstudy</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/example.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Example-of-using-litstudy">
<h1>Example of using litstudy<a class="headerlink" href="#Example-of-using-litstudy" title="Permalink to this heading"></a></h1>
<p>This notebook shows an example of how to use <code class="docutils literal notranslate"><span class="pre">litstudy</span></code> from inside a Jupyter notebook. It shows how to load a dataset, plot statistics, perform topic modeling, do network analysis, and some more advanced features.</p>
<p>This notebook focuses on the topic of programming model for GPUs. GPUs (Graphic Processing Units) are specialized processors that are used in many data centers and supercomputers for data processing and machine learning. However, programming these devices remaining difficult, which is why there is a plethora of research on developing programming models for GPUs.</p>
<section id="Imports">
<h2>Imports<a class="headerlink" href="#Imports" title="Permalink to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import other libraries</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sbs</span>

<span class="c1"># Options for plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s1">&#39;paper&#39;</span><span class="p">)</span>

<span class="c1"># Import litstudy</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">))</span>
<span class="k">if</span> <span class="n">path</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">litstudy</span>
</pre></div>
</div>
</div>
</section>
<section id="Collecting-the-dataset">
<h2>Collecting the dataset<a class="headerlink" href="#Collecting-the-dataset" title="Permalink to this heading"></a></h2>
<p>For this example, we have queried both IEEE Xplore and Springer Link for <code class="docutils literal notranslate"><span class="pre">&quot;GPU&quot;</span> <span class="pre">and</span> <span class="pre">&quot;programming</span> <span class="pre">model&quot;</span></code>. IEEE Xplore gives 5 CSV files (1 per page) and Springer Link gives a single CSV file. We load all files document sets and merge the resulting document sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the CSV files</span>
<span class="n">docs1</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ieee_csv</span><span class="p">(</span><span class="s1">&#39;data/ieee_1.csv&#39;</span><span class="p">)</span>
<span class="n">docs2</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ieee_csv</span><span class="p">(</span><span class="s1">&#39;data/ieee_2.csv&#39;</span><span class="p">)</span>
<span class="n">docs3</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ieee_csv</span><span class="p">(</span><span class="s1">&#39;data/ieee_3.csv&#39;</span><span class="p">)</span>
<span class="n">docs4</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ieee_csv</span><span class="p">(</span><span class="s1">&#39;data/ieee_4.csv&#39;</span><span class="p">)</span>
<span class="n">docs5</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ieee_csv</span><span class="p">(</span><span class="s1">&#39;data/ieee_5.csv&#39;</span><span class="p">)</span>
<span class="n">docs_ieee</span> <span class="o">=</span> <span class="n">docs1</span> <span class="o">|</span> <span class="n">docs2</span> <span class="o">|</span> <span class="n">docs3</span> <span class="o">|</span> <span class="n">docs4</span> <span class="o">|</span> <span class="n">docs5</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_ieee</span><span class="p">),</span> <span class="s1">&#39;papers loaded from IEEE&#39;</span><span class="p">)</span>

<span class="n">docs_springer</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_springer_csv</span><span class="p">(</span><span class="s1">&#39;data/springer.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_springer</span><span class="p">),</span> <span class="s1">&#39;papers loaded from Springer&#39;</span><span class="p">)</span>

<span class="c1"># Merge the two document sets</span>
<span class="n">docs_csv</span> <span class="o">=</span> <span class="n">docs_ieee</span> <span class="o">|</span> <span class="n">docs_springer</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_csv</span><span class="p">),</span> <span class="s1">&#39;papers loaded from CSV&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
441 papers loaded from IEEE
1000 papers loaded from Springer
1441 papers loaded from CSV
</pre></div></div>
</div>
<p>We can also exclude some papers that we are not interested in. Here, we load a document set from a RIS file and subtract these documents from our original document set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs_exclude</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">load_ris_file</span><span class="p">(</span><span class="s1">&#39;data/exclude.ris&#39;</span><span class="p">)</span>
<span class="n">docs_remaining</span> <span class="o">=</span> <span class="n">docs_csv</span> <span class="o">-</span> <span class="n">docs_exclude</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_exclude</span><span class="p">),</span> <span class="s1">&#39;papers were excluded&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_remaining</span><span class="p">),</span> <span class="s1">&#39;paper remaining&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1 papers were excluded
1440 paper remaining
</pre></div></div>
</div>
<p>The amount metadata provided by the CSV files is minimal. To enhance the metadata, we can find the corresponding articles on Scopus using <code class="docutils literal notranslate"><span class="pre">refine_scopus</span></code>. This function returns two sets: the set of documents that were found on Scopus and the set of original documents not were not found. We have two options on how to handle these two sets: (1) merge the two sets back into one set or (2) discard the documents that were not found. We chose the second option here for simplicity.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">CRITICAL</span><span class="p">)</span>

<span class="n">docs_scopus</span><span class="p">,</span> <span class="n">docs_notfound</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">refine_scopus</span><span class="p">(</span><span class="n">docs_remaining</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_scopus</span><span class="p">),</span> <span class="s1">&#39;papers found on Scopus&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_notfound</span><span class="p">),</span> <span class="s1">&#39;papers were not found and were discarded&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 1440/1440 [00:03&lt;00:00, 361.20it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1387 papers found on Scopus
53 papers were not found and were discarded
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>Next, we plot the number of documents per publication source.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_year_histogram</span><span class="p">(</span><span class="n">docs_scopus</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_11_0.png" src="_images/example_11_0.png" />
</div>
</div>
<p>In this example, we discover that one document was published in 1997. This document should not be in our set since GPUs were not used for general purpose computing before 2006. We can remove this document by filtering on year of publication.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">docs_scopus</span><span class="o">.</span><span class="n">filter_docs</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="o">.</span><span class="n">publication_year</span> <span class="o">&gt;=</span> <span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Print how many papers are left</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">),</span> <span class="s1">&#39;papers remaining&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1386 papers remaining
</pre></div></div>
</div>
</section>
<section id="General-statistics">
<h2>General statistics<a class="headerlink" href="#General-statistics" title="Permalink to this heading"></a></h2>
<p>litstudy supports plot many general statistics of the document set as histograms. We show some simple examples below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_year_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">vertical</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_18_0.png" src="_images/example_18_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_affiliation_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">15</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_19_0.png" src="_images/example_19_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_author_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_20_0.png" src="_images/example_20_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_language_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_21_0.png" src="_images/example_21_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_number_authors_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_22_0.png" src="_images/example_22_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This names are long, which is why a short abbreviation is provided.</span>
<span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;IEEE International parallel and distributed processing symposium IPDPS&quot;</span><span class="p">:</span> <span class="s2">&quot;IEEE IPDPS&quot;</span><span class="p">,</span>
    <span class="s2">&quot;IEEE International parallel and distributed processing symposium workshops IPDPSW&quot;</span><span class="p">:</span> <span class="s2">&quot;IEEE IPDPS Workshops&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_source_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">mapper</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">15</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_23_0.png" src="_images/example_23_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_country_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">15</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_24_0.png" src="_images/example_24_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_continent_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_25_0.png" src="_images/example_25_0.png" />
</div>
</div>
</section>
<section id="Network-analysis">
<h2>Network analysis<a class="headerlink" href="#Network-analysis" title="Permalink to this heading"></a></h2>
<p>The network below shows an example of a co-citation network. This is a type of network where nodes represent documents and edges represent pairs of documents that have been cited together simulatenously by other papers. The strength of the edges indicates how often two documents have been cited together. Two papers with a high co-citation strength (i.e., stronger edge) are usually highly related.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">plot_cocitation_network</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">max_edges</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 1000/1000 [00:00&lt;00:00, 1752.38it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
BarnesHut Approximation  took  0.14  seconds
Repulsion forces  took  0.32  seconds
Gravitational forces  took  0.01  seconds
Attraction forces  took  0.01  seconds
AdjustSpeedAndApplyForces step  took  0.04  seconds
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<iframe
    width="100%"
    height="1000px"
    src="citation.html"
    frameborder="0"
    allowfullscreen
></iframe></div>
</div>
</section>
<section id="Topic-modeling">
<h2>Topic modeling<a class="headerlink" href="#Topic-modeling" title="Permalink to this heading"></a></h2>
<p>litstudy supports automatic topic discovery based on the words used in documents abstracts. We show an example below. First, we need to build a corpus from the document set. Note that <code class="docutils literal notranslate"><span class="pre">build_corpus</span></code> supports many arguments to tweak the preprocessing stage of building the corpus. In this example, we pass <code class="docutils literal notranslate"><span class="pre">ngram_threshold=0.85</span></code>. This argument adds commonly used n-grams (i.e., frequent consecutive words) to the corpus. For instance, <code class="docutils literal notranslate"><span class="pre">artificial</span></code> and <code class="docutils literal notranslate"><span class="pre">intelligence</span></code> is a bigram, so a token
<code class="docutils literal notranslate"><span class="pre">artificial_intelligence</span></code> is added to the corpus.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">build_corpus</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">ngram_threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can compute a word distribution using <code class="docutils literal notranslate"><span class="pre">litstudy.compute_word_distribution</span></code> which shows how often each word occurs across all documents. In this example, we focus only on n-grams by selecting tokens that contain a <code class="docutils literal notranslate"><span class="pre">_</span></code>. We see that words such as <code class="docutils literal notranslate"><span class="pre">artificial</span> <span class="pre">intelligence</span></code> and <code class="docutils literal notranslate"><span class="pre">trade</span> <span class="pre">offs</span></code> indeed have been recognized as common bigrams.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">litstudy</span><span class="o">.</span><span class="n">compute_word_distribution</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">like</span><span class="o">=</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>artificial_intelligence</th>
      <td>13</td>
    </tr>
    <tr>
      <th>author_exclusive</th>
      <td>41</td>
    </tr>
    <tr>
      <th>berlin_heidelberg</th>
      <td>83</td>
    </tr>
    <tr>
      <th>chinese_academy</th>
      <td>6</td>
    </tr>
    <tr>
      <th>coarse_grained</th>
      <td>16</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>synthetic_aperture</th>
      <td>7</td>
    </tr>
    <tr>
      <th>trade_offs</th>
      <td>10</td>
    </tr>
    <tr>
      <th>unified_device</th>
      <td>108</td>
    </tr>
    <tr>
      <th>xeon_phi</th>
      <td>21</td>
    </tr>
    <tr>
      <th>zhejiang_university</th>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>63 rows × 1 columns</p>
</div></div>
</div>
<p>Let’s visualize the word distribution from this corpus.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_word_distribution</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Top words&quot;</span><span class="p">,</span> <span class="n">vertical</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label_rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_35_0.png" src="_images/example_35_0.png" />
</div>
</div>
<p>This word distribution looks normal. Next, we train an NMF topic model. Topic modeling is a technique from natural language processing for discovering abstract &quot;topics&quot; in a set of document. We need to manually select the number of desired topics. Here we choose 15 topics. It is recommended to experiment with more or less topics to obtain topics that are more fine-grained or more coarse-grained</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_topics</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">train_nmf_model</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>To understand the result of NMF, we can print the top 3 words for each topic.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_topics</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Topic </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">,</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">best_tokens_for_topic</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Topic 1: [&#39;cluster&#39;, &#39;mpi&#39;, &#39;node&#39;, &#39;hybrid&#39;, &#39;communication&#39;]
Topic 2: [&#39;mapreduce&#39;, &#39;big&#39;, &#39;data&#39;, &#39;hadoop&#39;, &#39;cloud&#39;]
Topic 3: [&#39;simulation&#39;, &#39;particle&#39;, &#39;numerical&#39;, &#39;fluid&#39;, &#39;flow&#39;]
Topic 4: [&#39;learning&#39;, &#39;network&#39;, &#39;deep&#39;, &#39;deep_learning&#39;, &#39;training&#39;]
Topic 5: [&#39;fpga&#39;, &#39;memory&#39;, &#39;access&#39;, &#39;cache&#39;, &#39;bandwidth&#39;]
Topic 6: [&#39;openacc&#39;, &#39;compiler&#39;, &#39;openmp&#39;, &#39;directive&#39;, &#39;language&#39;]
Topic 7: [&#39;image&#39;, &#39;segmentation&#39;, &#39;algorithm&#39;, &#39;medical&#39;, &#39;sensing&#39;]
Topic 8: [&#39;sequence&#39;, &#39;alignment&#39;, &#39;protein&#39;, &#39;database&#39;, &#39;search&#39;]
Topic 9: [&#39;video&#39;, &#39;decoding&#39;, &#39;encoding&#39;, &#39;ldpc&#39;, &#39;motion&#39;]
Topic 10: [&#39;gpgpu&#39;, &#39;cuda&#39;, &#39;code&#39;, &#39;general_purpose&#39;, &#39;general&#39;]
Topic 11: [&#39;energy&#39;, &#39;heterogeneous&#39;, &#39;power&#39;, &#39;consumption&#39;, &#39;systems&#39;]
Topic 12: [&#39;graph&#39;, &#39;vertex&#39;, &#39;framework&#39;, &#39;analytics&#39;, &#39;edge&#39;]
Topic 13: [&#39;scheduling&#39;, &#39;task&#39;, &#39;heterogeneous&#39;, &#39;resources&#39;, &#39;execution&#39;]
Topic 14: [&#39;intel&#39;, &#39;matrix&#39;, &#39;phi&#39;, &#39;xeon&#39;, &#39;cloud&#39;]
Topic 15: [&#39;opencl&#39;, &#39;portability&#39;, &#39;benchmark&#39;, &#39;platforms&#39;, &#39;sycl&#39;]
</pre></div></div>
</div>
<p>An alternative way to visualize the output of NMF is to plot each discovered topic as a word cloud. The size of each word in a cloud indicate the importance of that word for that topic.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_topic_clouds</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_41_0.png" src="_images/example_41_0.png" />
</div>
</div>
<p>These 15 topics look promising. For example, there is one topic on graphs, one on OpenACC (the open accelerators programming standard), one on OpenCL (the open compute language), one on FPGAs (field-programmable gate array), etc.</p>
<p>We can visualize the results as a &quot;landscape&quot; plot. This is a visual appealing way to place documents on 2D plane. The documents are placed such that similar documents are located closed to each other. However, this is a non-linear embedding so the distances between the documents are not linear.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_embedding</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">topic_model</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_43_0.png" src="_images/example_43_0.png" />
</div>
</div>
</section>
<section id="Advanced-topic-modeling">
<h2>Advanced topic modeling<a class="headerlink" href="#Advanced-topic-modeling" title="Permalink to this heading"></a></h2>
<p>We can combine the results of topic modeling with the plotting of statistics. Here we show we a simple example.</p>
<p>One of the topics appears to be on &quot;deep_learning&quot;. First, we find the topic id for the topic that most strongly belongs to &quot;deep_learning&quot;.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topic_id</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">best_topic_for_token</span><span class="p">(</span><span class="s1">&#39;deep_learning&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s print the top 10 papers that most stongly belong to this topic to check the results. We see that these are indeed documents on the topic of deep learning.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">best_documents_for_topic</span><span class="p">(</span><span class="n">topic_id</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)]</span><span class="o">.</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
High performance networked computing in media, services and information management
What do Programmers Discuss about Deep Learning Frameworks
Sparse evolutionary deep learning with over one million artificial neurons on commodity hardware
Deep learning for intelligent traffic sensing and prediction: recent advances and future challenges
SOLAR: Services-oriented learning architectures: Deep learning as a service
Reveal training performance mystery between TensorFlow and PyTorch in the single GPU environment
Network Management 2030: Operations and Control of Network 2030 Services
SOLAR: Services-Oriented Deep Learning Architectures-Deep Learning as a Service
DLPlib: A Library for Deep Learning Processor
Machine Learning and Deep Learning frameworks and libraries for large-scale data mining: a survey
</pre></div></div>
</div>
<p>Next, we annotate the document set with a &quot;dl_topic&quot; tag for document that strongly belong to this topic (i.e., weight above a certain threshold).</p>
<p>After this, we define two groups: documents that have the tag &quot;dl_topic&quot; and documents that do not have this tag. Now we can, for instance, print the publications over the years to see if interest in deep learning has increased or decreased over the years.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">dl_topic</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">doc2topic</span><span class="p">[:,</span> <span class="n">topic_id</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">docs</span><span class="o">.</span><span class="n">add_property</span><span class="p">(</span><span class="s1">&#39;dl_topic&#39;</span><span class="p">,</span> <span class="n">dl_topic</span><span class="p">)</span>


<span class="n">groups</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;deep learning related&#39;</span><span class="p">:</span> <span class="s1">&#39;dl_topic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;other&#39;</span><span class="p">:</span> <span class="s1">&#39;not dl_topic&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_year_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_50_0.png" src="_images/example_50_0.png" />
</div>
</div>
<p>The histogram shows that interest in deep learning has clearly risen over the years. We can even calculate the exact amount by calculating the percentage of documents on deep learning each year. The example below shows that this percentage has increased from just 3.4% in 2011 to 13.6% in 2021.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">compute_year_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
<span class="n">table</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>deep learning related</th>
      <th>other</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2005</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2007</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>6.250000</td>
      <td>93.750000</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>0.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>2.127660</td>
      <td>97.872340</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>3.409091</td>
      <td>96.590909</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>2.941176</td>
      <td>97.058824</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>3.738318</td>
      <td>96.261682</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>3.305785</td>
      <td>96.694215</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>9.565217</td>
      <td>90.434783</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>7.272727</td>
      <td>92.727273</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>3.448276</td>
      <td>96.551724</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>7.200000</td>
      <td>92.800000</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>9.027778</td>
      <td>90.972222</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>9.734513</td>
      <td>90.265487</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>13.600000</td>
      <td>86.400000</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>14.285714</td>
      <td>85.714286</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Alternatively, we can plot the two groups for the publications source. We can see that some journals/conferences have a strong focus on deep learning (e.g. &quot;Neural Computing and Applications&quot;), while others have no or few publications on deep learning (e.g. &quot;Journal of Real Time Image Processing&quot;).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">litstudy</span><span class="o">.</span><span class="n">plot_source_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_54_0.png" src="_images/example_54_0.png" />
</div>
</div>
<p>We can even calculate the most popular publication venues for deep learning in our dataset using some simple Panda functions. It appears that &quot;Neural Computing and Applications&quot; is the most popular publication venue.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute histogram by publication venue</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">litstudy</span><span class="o">.</span><span class="n">compute_source_histogram</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>

<span class="c1"># Add column &#39;total&#39;</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;deep learning related&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;other&#39;</span><span class="p">]</span>

<span class="c1"># Remove rare venues that have less than 5 publications</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">]</span>

<span class="c1"># Add column &#39;ratio&#39;</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;deep learning related&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>

<span class="c1"># Sort by ratio in descending order</span>
<span class="n">table</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;ratio&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>deep learning related</th>
      <th>other</th>
      <th>total</th>
      <th>ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Neural Computing and Applications</th>
      <td>3</td>
      <td>3</td>
      <td>6</td>
      <td>50.000000</td>
    </tr>
    <tr>
      <th>Computing</th>
      <td>3</td>
      <td>12</td>
      <td>15</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>IEEE International Symposium on Workload Characterization IISWC</th>
      <td>1</td>
      <td>4</td>
      <td>5</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>Science China Information Sciences</th>
      <td>2</td>
      <td>8</td>
      <td>10</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>IEEE High Performance Extreme Computing Conference HPEC</th>
      <td>1</td>
      <td>7</td>
      <td>8</td>
      <td>12.500000</td>
    </tr>
    <tr>
      <th>European Physical Journal C</th>
      <td>1</td>
      <td>7</td>
      <td>8</td>
      <td>12.500000</td>
    </tr>
    <tr>
      <th>Journal of Grid Computing</th>
      <td>1</td>
      <td>7</td>
      <td>8</td>
      <td>12.500000</td>
    </tr>
    <tr>
      <th>Journal of Computer Science and Technology</th>
      <td>3</td>
      <td>21</td>
      <td>24</td>
      <td>12.500000</td>
    </tr>
    <tr>
      <th>Multimedia Tools and Applications</th>
      <td>3</td>
      <td>25</td>
      <td>28</td>
      <td>10.714286</td>
    </tr>
    <tr>
      <th>Journal of Supercomputing</th>
      <td>20</td>
      <td>205</td>
      <td>225</td>
      <td>8.888889</td>
    </tr>
    <tr>
      <th>BMC Bioinformatics</th>
      <td>2</td>
      <td>22</td>
      <td>24</td>
      <td>8.333333</td>
    </tr>
    <tr>
      <th>Journal of Big Data</th>
      <td>1</td>
      <td>11</td>
      <td>12</td>
      <td>8.333333</td>
    </tr>
    <tr>
      <th>Cluster Computing</th>
      <td>3</td>
      <td>52</td>
      <td>55</td>
      <td>5.454545</td>
    </tr>
    <tr>
      <th>International Journal of Parallel Programming</th>
      <td>5</td>
      <td>87</td>
      <td>92</td>
      <td>5.434783</td>
    </tr>
    <tr>
      <th>IEEE International Parallel and Distributed Processing Symposium Workshops IPDPSW</th>
      <td>1</td>
      <td>21</td>
      <td>22</td>
      <td>4.545455</td>
    </tr>
    <tr>
      <th>Journal of Signal Processing Systems</th>
      <td>1</td>
      <td>42</td>
      <td>43</td>
      <td>2.325581</td>
    </tr>
    <tr>
      <th>Soft Computing</th>
      <td>0</td>
      <td>16</td>
      <td>16</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>BMC Research Notes</th>
      <td>0</td>
      <td>6</td>
      <td>6</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Journal of the Brazilian Society of Mechanical Sciences and Engineering</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE International Conference on Cluster Computing CLUSTER</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE International Symposium on High Performance Computer Architecture HPCA</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE International Conference on Parallel and Distributed Systems ICPADS</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Journal of Real Time Image Processing</th>
      <td>0</td>
      <td>57</td>
      <td>57</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Journal of Scientific Computing</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Computing and Visualization in Science</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Visual Computer</th>
      <td>0</td>
      <td>7</td>
      <td>7</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE ACM International Symposium on Cluster Cloud and Grid Computing CCGrid</th>
      <td>0</td>
      <td>6</td>
      <td>6</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Euromicro International Conference on Parallel Distributed and Network Based Processing PDP</th>
      <td>0</td>
      <td>6</td>
      <td>6</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE Transactions on Parallel and Distributed Systems</th>
      <td>0</td>
      <td>7</td>
      <td>7</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>International Conference for High Performance Computing Networking Storage and Analysis SC</th>
      <td>0</td>
      <td>7</td>
      <td>7</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Frontiers of Computer Science</th>
      <td>0</td>
      <td>8</td>
      <td>8</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>VLDB Journal</th>
      <td>0</td>
      <td>8</td>
      <td>8</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Computer Science Research and Development</th>
      <td>0</td>
      <td>10</td>
      <td>10</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>IEEE International Parallel and Distributed Processing Symposium IPDPS</th>
      <td>0</td>
      <td>11</td>
      <td>11</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>International Conference on High Performance Computing and Simulation HPCS</th>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="faq.html" class="btn btn-neutral float-right" title="Frequently Asked Questions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, S. Heldens, H. Dreuning, A. Sclocco.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>